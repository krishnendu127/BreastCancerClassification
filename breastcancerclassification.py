# -*- coding: utf-8 -*-
"""BreastCancerClassification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MfpD1HUlwuGJS4B7A5FOiRNmP4N9MSim
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import sklearn.datasets
from sklearn.model_selection import train_test_split

#loading the data from sklearn
breast_cancer_dataset=sklearn.datasets.load_breast_cancer()

print(breast_cancer_dataset)

#loading into a dataframe
data_frame=pd.DataFrame(breast_cancer_dataset.data, columns= breast_cancer_dataset.feature_names)

#adding the target column to the dataframe
data_frame['label']= breast_cancer_dataset.target

#print first 5 rows
data_frame.head()

data_frame.shape

data_frame.describe()

data_frame['label'].value_counts()

"""1-> Benign
0-> Malignant
"""

data_frame.groupby('label').mean()

X=data_frame.drop(columns='label',axis=1)
Y=data_frame['label']

print(X)

print(Y)

X_train , X_test, Y_train, Y_test=train_test_split(X,Y,test_size=0.2, random_state=2)

"""standardizing the data"""

from sklearn.preprocessing import StandardScaler
scaler= StandardScaler()
X_trainstd=scaler.fit_transform(X_train)
X_teststd=scaler.transform(X_test)

"""Building the neural network"""

#importing tenserflow and keras
import tensorflow as tf
tf.random.set_seed(3)
from tensorflow import keras

#setting up the layers of neural network
model= keras.Sequential([
    keras.layers.Flatten(input_shape=(30,)),
    keras.layers.Dense(20, activation='relu'),
    keras.layers.Dense(2, activation='sigmoid')
])

#compiling the neural network
 model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

"""one hot encoding

"""

#training the neural network

history=model.fit(X_train, Y_train, validation_split=0.1,epochs=10)

# training with standardized data
history=model.fit(X_trainstd, Y_train, validation_split=0.1,epochs=10)

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['training data','validation data'], loc='lower right')

"""accuracy of model on test data"""

loss, accuracy=model.evaluate(X_teststd, Y_test)
print(accuracy)

#my first data
print(X_teststd[0])

Y_pred= model.predict(X_teststd)

print(Y_pred.shape)
print(Y_pred[0])

print(Y_test)

print(Y_pred)

#model.predict gives the prediction probabilty of each data point

#argmax function
my_list = [10,20,30]
indexofmaxval=np.argmax(my_list)
print(indexofmaxval)

"""using the above logic we apply this to each data point above and we get the maximum value out of the predicted two values for each data point"""

Y_pred_labels= [np.argmax(i) for i in Y_pred]
print(Y_pred_labels)

"""building the predictive system

"""

input_data=(11.76,21.6,74.72,427.9,0.08637,0.04966,0.01657,0.01115,0.1495,0.05888,0.4062,1.21,2.635,28.47,0.005857,0.009758,0.01168,0.007445,0.02406,0.001769,12.98,25.72,82.98,516.5,0.1085,0.08615,0.05523,0.03715,0.2433,0.06563)
#change the input data to a numpy array
input_data_np=np.array(input_data)

#reshape the numpy array as we are prediciting for one data point
input_data_reshaped= input_data_np.reshape(1,-1)

#standardizing the input data
input_data_std=scaler.transform(input_data_reshaped)

prediction=model.predict(input_data_std)
print(prediction)

prediction_label= [np.argmax(prediction)]
print(prediction_label)

if(prediction_label[0] == 0):
  print("the tumor is maligant")
else :
  print("the tumor is benign")

